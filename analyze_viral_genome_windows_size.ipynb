{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tests: is the major act of exclusion legit? e.g. is every guy excluded not a real virus, and is every guy included a real virus (latter easily verified by checking taxonomy id)\n",
    "\n",
    "can check everything acc in the following: in/out of acc2taxid, in/out of fasta, map to in/out of human virus taxonomy (<= 8 combos) in RVDB fasta, in acc2taxid, map to in human virus taxonomy:\n",
    "\n",
    "- NC_001798 (Human herpesvirus 2)\n",
    "- NC_005218 (Hantaan virus)\n",
    "\n",
    "in RVDB fasta, in acc2taxid, do not map to human virus taxonomy incorrectly:\n",
    "\n",
    "- MH701568 (Influenza A virus (A/California/SEA0134/2018(H3N2)))\n",
    "- KY493188 (human T-lymphotropic virus-1)\n",
    "- KC986396.2 (Influenza A virus (A/equine/Heilongjiang/SS1/2013(H3N8)))\n",
    "- MH213608.1 (rubella)\n",
    "- CY233611.1 (Influenza B virus (B/Connecticut/26/2017))\n",
    "- AH007825.2 (human T-lymphotropic virus-2)\n",
    "\n",
    "in RVDB fasta, in acc2taxid, do not map to human virus taxonomy correctly:\n",
    "\n",
    "- HQ330496.1 (avian nephritis)\n",
    "- NC_030692.1 (Borna disease virus)\n",
    "\n",
    "could compare number of human mentions to number of viruses actually flagged\n",
    "\n",
    "sequences bounded below by uniques just from human viruses tsv (in fact, inclusion)\n",
    "\n",
    "bounded above by all virus lengths?\n",
    "\n",
    "\"1 million of the 2.7 million sequences had such a mention, which is\n",
    "likely a lower bound for the number of human viruses\"\n",
    "\n",
    "individual viruses and numbers too\n",
    "\n",
    "second type of test is whether, once we have the right set of viruses,\n",
    "the sequence set is legit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slackclient\n",
    "# TODO: could config this out if I'm worried about spam to slack\n",
    "token = 'xoxp-3285562789-3285562791-619656394981-ef7c0f6526661e83a1561d9d1a742d22'\n",
    "sc = slackclient.SlackClient(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/a/5320179\n",
    "# low-priority: test this more exhaustively (do we believe that \"find_whole_word('flu') is not None\" won't find exactly all flu viruses? not sure... maybe \"flu-like\")\n",
    "def find_whole_word(w, flags=re.IGNORECASE):\n",
    "    return re.compile(r'\\b({0})\\b'.format(w), flags=flags).search\n",
    "\n",
    "find_flu = find_whole_word('flu')\n",
    "assert find_flu('flu') is not None\n",
    "assert find_flu('aksdjflkaj') is None\n",
    "assert find_flu('flue') is None\n",
    "assert find_flu('flu|1234') is not None\n",
    "assert find_flu('flu-like virus') is not None\n",
    "assert find_flu('Human orthopneumovirus (HRSV) Subgroup B, complete genome') is None\n",
    "\n",
    "find_influenza = find_whole_word('influenza')\n",
    "assert find_influenza('influenza') is not None\n",
    "assert find_influenza('Influenza A virus (A/Puerto Rico/8/1934(H1N1)) segment 1, complete sequence') is not None\n",
    "assert find_influenza('Influenza B virus RNA 1, complete sequence') is not None\n",
    "assert find_influenza('Influenza B virus (B/Lee/1940) segment 2, complete sequence.') is not None\n",
    "assert find_influenza('Influenza C virus (C/Ann Arbor/1/50) PB2 gene for polymerase 2, complete cds.') is not None\n",
    "assert find_influenza('Human parainfluenza virus 1, complete genome') is None\n",
    "assert find_influenza('Human orthopneumovirus (HRSV) Subgroup B, complete genome') is None\n",
    "\n",
    "find_human_immunodeficiency_virus = find_whole_word('human immunodeficiency virus')\n",
    "assert find_human_immunodeficiency_virus('human immunodeficiency virus') is not None\n",
    "assert find_human_immunodeficiency_virus('immunodeficiency virus') is None\n",
    "assert find_human_immunodeficiency_virus('Human immunodeficiency virus 1, complete genome') is not None\n",
    "assert find_human_immunodeficiency_virus('Simian immunodeficiency virus (SIV) - SIVagmMAL genomic RNA, complete genome, strain: ZMB') is None\n",
    "\n",
    "find_hiv = find_whole_word('hiv')\n",
    "assert find_hiv('hiv') is not None\n",
    "assert find_hiv('chives') is None\n",
    "assert find_hiv('hiv-1') is not None\n",
    "assert find_hiv('Human immunodeficiency virus 1 (HIV-1)|1234') is not None\n",
    "assert find_hiv('Simian immunodeficiency virus (SIV) - SIVagmMAL genomic RNA, complete genome, strain: ZMB') is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stonger upper bound of number of winodws in RVDB; counts unique k-mer windows.\n",
    "# In general, prefer this to sequence length-based upper bound if possible.\n",
    "# Downside is large memory requirement: I got a m5a.12xlarge machine with 192 GB RAM.\n",
    "dna_window_size = 42\n",
    "excl_influenza = True\n",
    "excl_hiv = True\n",
    "start = datetime.datetime.now()\n",
    "upper_bound_all_rvdb_windows = set()\n",
    "num_seqs_seen = 0\n",
    "seqs = SeqIO.parse(\"data/U-RVDBv15.1.fasta\", \"fasta\")\n",
    "num_flu = 0\n",
    "num_influenza = 0\n",
    "num_human_immunodeficiency_virus = 0\n",
    "num_hiv = 0\n",
    "for seq in seqs:\n",
    "    num_seqs_seen += 1\n",
    "    # start testing\n",
    "#     if num_seqs_seen not in range(163217, 163217 + 1000):\n",
    "#         break\n",
    "    # end testing\n",
    "    if num_seqs_seen % 100000 == 0:\n",
    "        print(num_seqs_seen)\n",
    "    excl = False\n",
    "    if excl_influenza:\n",
    "        if find_flu(seq.description) is not None:\n",
    "            # start testing\n",
    "#             print('found flu')\n",
    "#             print(seq)\n",
    "            # end testing\n",
    "            num_flu += 1\n",
    "            excl = True\n",
    "        if find_influenza(seq.description) is not None:\n",
    "            # start testing\n",
    "#             print('found influenza')\n",
    "#             print(seq)\n",
    "            # end testing\n",
    "            num_influenza += 1\n",
    "            excl = True\n",
    "        if find_human_immunodeficiency_virus(seq.description) is not None:\n",
    "            # start testing\n",
    "#             print('found influenza')\n",
    "#             print(seq)\n",
    "            # end testing\n",
    "            num_human_immunodeficiency_virus += 1\n",
    "            excl = True\n",
    "        if find_hiv(seq.description) is not None:\n",
    "            # start testing\n",
    "#             print('found influenza')\n",
    "#             print(seq)\n",
    "            # end testing\n",
    "            num_hiv += 1\n",
    "            excl = True\n",
    "    if excl:\n",
    "        continue\n",
    "        # start testing\n",
    "#         else:\n",
    "#             print('found nothing')\n",
    "#             print(seq)\n",
    "        # end testing\n",
    "    sequence = str(seq.seq)\n",
    "    for i in range(len(sequence)-(dna_window_size-1)):\n",
    "        upper_bound_all_rvdb_windows.add(sequence[i:(i+dna_window_size)])\n",
    "sc.api_call(\"chat.postMessage\", channel=\"#bot\",text=f'done generating unique {dna_window_size}-mers, took {(datetime.datetime.now() - start).seconds}s')\n",
    "print(f'{num_flu} sequences with flu')\n",
    "print(f'{num_influenza} sequences with influenza')\n",
    "print(f'{num_human_immunodeficiency_virus} sequences with human immunodeficiency virus')\n",
    "print(f'{num_hiv} sequences with hiv')\n",
    "print(f'{len(upper_bound_all_rvdb_windows)} unique {dna_window_size}-mers when excl_influenza = {excl_influenza}, excl_hiv = {excl_hiv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 39-mers, the above result is\n",
    "\n",
    "- 2 sequences with flu\n",
    "- 661118 sequences with influenza\n",
    "- 814283 sequences with human immunodeficiency virus\n",
    "- 759673 sequences with hiv\n",
    "- 471495384 unique 39-mers when excl_influenza = True, excl_hiv = True\n",
    "\n",
    "For 42-mers, the above result is\n",
    "\n",
    "- 2 sequences with flu\n",
    "- 661118 sequences with influenza\n",
    "- 814283 sequences with human immunodeficiency virus\n",
    "- 759673 sequences with hiv\n",
    "- 486339373 unique 42-mers when excl_influenza = True, excl_hiv = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of unique 19aa-mers in RVDB-prot, to sanity check and determine how much of the sequenced global virome is not protein coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A check of https://www.ncbi.nlm.nih.gov/nucleotide/NC_001798.2 and all sequences in '-prot.fasta' with a matching accession code suggests that each entry in U-RVDB-prot corresponds to a \"CDS /translation\" features on an NCBI page like this. This reasonably reconciles 2.7mn viral genomes with 3.9mn proteins. This matches Debbie Marks's claim that the viral genome is poorly annotated (1.3 proteins per genome?). So I understand the source of the flat file a bit (CDSs, although I don't know who annotates those CDSs). But yeah, we can produce a prelim estimate, unless it turns out the HMM stuff overrides the flat file.\n",
    "\n",
    "And then I still need to figure out what the HMM stuff actually is. I understand that these HMM profiles are just groupings of the RVDB proteins (likely?). Doesn’t really change that we’re going to use the flat files. The purpose of these families: is it to make searches more efficient? If so, that’s not my concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "prot_seqs = SeqIO.parse(\"data/U-RVDBv15.1-prot.fasta\", \"fasta\")\n",
    "aa_window_size = 19\n",
    "upper_bound_all_rvdb_aa_windows = set()\n",
    "num_seqs_seen = 0\n",
    "for seq in prot_seqs:\n",
    "    num_seqs_seen += 1\n",
    "    if num_seqs_seen % 100000 == 0:\n",
    "        print(num_seqs_seen)\n",
    "    sequence = str(seq.seq)\n",
    "    for i in range(len(sequence)-(aa_window_size-1)):\n",
    "        upper_bound_all_rvdb_aa_windows.add(sequence[i:(i+aa_window_size)])\n",
    "sc.api_call(\"chat.postMessage\", channel=\"#bot\",text=f'done generating unique {aa_window_size}-mers, took {(datetime.datetime.now() - start).seconds}s')\n",
    "print(f'{len(upper_bound_all_rvdb_aa_windows)} unique {aa_window_size}-mers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA vs. DNA viruses?\n",
    "\n",
    "One approach: check distinct nucleotides, maybe even histogram it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = SeqIO.parse(\"data/U-RVDBv15.1.fasta\", \"fasta\")\n",
    "nucleotide_counts = defaultdict(int)\n",
    "num_seqs_seen = 0\n",
    "for seq in seqs:\n",
    "    num_seqs_seen += 1\n",
    "    if num_seqs_seen % 100000 == 0:\n",
    "        print(num_seqs_seen)\n",
    "    for char in seq.seq:\n",
    "        nucleotide_counts[char] += 1\n",
    "\n",
    "print(nucleotide_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weak upper bound of number of winodws in RVDB; counts sequence lengths.\n",
    "# In general, don't use if can count number of unique windows.\n",
    "upper_bound_num_rvdb_windows = 0\n",
    "seqs = SeqIO.parse(\"data/U-RVDBv15.1.fasta\", \"fasta\")\n",
    "for seq in seqs:\n",
    "    upper_bound_num_rvdb_windows += max(len(seq)-38, 0)\n",
    "print(upper_bound_num_rvdb_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_fasta(acc, fasta_file):\n",
    "    seqs = SeqIO.parse(fasta_file, 'fasta')\n",
    "    acc = acc.split('.')[0] # remove version from accession number\n",
    "    for seq in seqs:\n",
    "        if acc in seq.id:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxid(acc, acc_to_taxid = None):\n",
    "    acc = acc.split('.')[0] # remove version from accession number\n",
    "    if acc_to_taxid is not None:\n",
    "        if acc in acc_to_taxid:\n",
    "            return(acc_to_taxid[acc])\n",
    "        return(None)\n",
    "    with open('data/nucl_gb.accession2taxid', 'rt') as f_acc2taxid:\n",
    "        reader_acc2taxid = csv.reader(f_acc2taxid, delimiter='\\t')\n",
    "        num_rows_seen = 0\n",
    "        for row in reader_acc2taxid:\n",
    "            num_rows_seen += 1\n",
    "            if num_rows_seen == 1: # header row\n",
    "                continue\n",
    "            if row[0] == acc:\n",
    "                return(row[2])\n",
    "    return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_at_index(index, fasta_file):\n",
    "    seqs = SeqIO.parse(fasta_file, 'fasta')\n",
    "    num_seqs_seen = -1\n",
    "    for seq in seqs:\n",
    "        num_seqs_seen += 1\n",
    "        if num_seqs_seen < index:\n",
    "            continue\n",
    "        elif num_seqs_seen == index:\n",
    "            return(seq)\n",
    "        elif num_seqs_seen > index:\n",
    "            break\n",
    "    return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid = get_taxid('HQ330496.1', acc_to_taxid)\n",
    "print(taxid)\n",
    "print(taxid is not None and taxid in human_virus_taxids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'2005264' in human_virus_taxids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on above results of repeatedly trying to sample viruses from RVDB\n",
    "# and getting human viruses, I'm actually down for the \"use everything\"\n",
    "# from RVDB strategy. I've done at least 10 samplings now, and they were\n",
    "# *all* human. That might be closer to the true number than one based on\n",
    "# viralzone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_in_fasta('NC_005218', 'data/U-RVDBv15.1.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = SeqIO.parse(\"data/U-RVDBv15.1.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tax IDs for viralzone viruses (as a proxy for human viruses)\n",
    "# Get the accession numbers from viralzone's human_viruses.tsv\n",
    "accs_viralzone = set()\n",
    "viruses_unavailable = set()\n",
    "with open('data/human_viruses.tsv', 'rt') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        row_accs = row[5]\n",
    "        if row_accs == 'Not available':\n",
    "            viruses_unavailable.add(row[0])\n",
    "        else:\n",
    "            for row_acc in re.split('\\W+', row[5]):\n",
    "                accs_viralzone.add(row_acc)\n",
    "                accs_viralzone.add(row_acc.replace('_', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map viralzone accs to tax ID numbers from a scan through nucl_wgs.accession2taxid that match\n",
    "start = datetime.datetime.now()\n",
    "human_virus_acc_to_taxid = dict()\n",
    "for acc in accs_viralzone:\n",
    "    taxid = get_taxid(acc, acc_to_taxid)\n",
    "    if taxid is not None:\n",
    "        human_virus_acc_to_taxid[acc] = get_taxid(acc, acc_to_taxid)\n",
    "human_virus_taxids = set(human_virus_acc_to_taxid.values())\n",
    "sc.api_call(\"chat.postMessage\", channel=\"#bot\",text=f'done checking existence of NC_s, took {(datetime.datetime.now() - start).seconds}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dictionary of accession numbers to taxids。\n",
    "# This memory-intensive step accounts for 35-45GB, since the dictionary\n",
    "# is large. Takes 243 seconds to generate on EC2 md5.4xlarge (64GB memory).\n",
    "# If someone desires to do this on a more memory-constrained computer,\n",
    "# they could edit load_acc_to_taxid to look through, say, 2 million rows in\n",
    "# the accession2taxid file, run the whole script once for each partition\n",
    "# of 2 million rows, and union all the results at the end.\n",
    "def load_acc_to_taxid():\n",
    "    acc_to_taxid = dict()\n",
    "    with open('data/nucl_gb.accession2taxid', 'rt') as f_acc2taxid:\n",
    "        reader_acc2taxid = csv.reader(f_acc2taxid, delimiter='\\t')\n",
    "        num_rows_seen = 0\n",
    "        for row in reader_acc2taxid:\n",
    "            num_rows_seen += 1\n",
    "            if num_rows_seen == 1: # header row\n",
    "                continue\n",
    "            acc_to_taxid[row[0]] = row[2]\n",
    "    return(acc_to_taxid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "acc_to_taxid = load_acc_to_taxid()\n",
    "sc.api_call(\"chat.postMessage\", channel=\"#bot\",text=f'done generating dictionary of accession numbers to tax ids, took {(datetime.datetime.now() - start).seconds}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_seqs = 0\n",
    "# accs = dict()\n",
    "# for seq in seqs:\n",
    "#     num_seqs += 1\n",
    "#     accs.add(seq.id.split('|')[2])\n",
    "# #     if num_seqs >= 20:\n",
    "# #         break\n",
    "# print(num_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(accs_rvdb_human_viruses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "# accs_rvdb_no_taxid = set()\n",
    "# accs_rvdb_human_viruses = set()\n",
    "# accs_rvdb_non_human_viruses = set()\n",
    "# human_virus_taxids_set = set(human_virus_taxids.values())\n",
    "# with open('data/nucl_gb.accession2taxid', 'rt') as f_acc2taxid:\n",
    "#     reader_acc2taxid = csv.reader(f_acc2taxid, delimiter='\\t')\n",
    "#     num_rows_seen = 0\n",
    "#     for row in reader_acc2taxid:\n",
    "#         num_rows_seen += 1\n",
    "#         if num_rows_seen == 1: # header row\n",
    "#             continue\n",
    "# #         if num_rows_seen >= 5000000:\n",
    "# #             break\n",
    "#         if row[1] in accs and row[2] in human_virus_taxids_set:\n",
    "#             accs_rvdb_human_viruses.add(row[1])\n",
    "#         elif row[1] not in accs:\n",
    "#             accs_rvdb_no_taxid.add(row[1])\n",
    "#         elif row[2] not in human_virus_taxids_set:\n",
    "#             accs_rvdb_non_human_viruses.add(row[1])\n",
    "# #         print(row[1])\n",
    "# #         print(row[2])\n",
    "# #         if num_rows_seen >= 50:\n",
    "# #             break\n",
    "# sc.api_call(\"chat.postMessage\", channel=\"#bot\",text=f'done checking existence of NC_s, took {(datetime.datetime.now() - start).seconds}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(accs_rvdb_human_viruses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unclear next time if I even need to start Jupyter with --NotebookApp.iopub_data_rate_limit=10000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set([acc for acc in accs_viralzone if '_' in acc]) - human_virus_taxids.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields = [None] * 5\n",
    "# num_seqs = 0\n",
    "# for seq in seqs:\n",
    "#     # First check ID fields have 4 fields\n",
    "#     seq_fields = seq.id.split('|')\n",
    "#     seq_fields[2] = seq_fields[2][0:2]\n",
    "#     # then check distribution of species, e.g.\n",
    "#     for i in range(len(seq_fields)):\n",
    "#         if fields[i] is None:\n",
    "#             fields[i] = defaultdict(int)\n",
    "#         fields[i][seq_fields[i]] += 1\n",
    "#     num_seqs += 1\n",
    "# print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_field3 = sorted(fields[3].items(), key=lambda kv: -kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_field3[0:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
